<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Introduction and Installation of CUDA on Mac</title>
  <meta name="description" content="  “You can’t connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in yourfu...">

  <link rel="canonical" href="https://junboychina.github.io/2016/07/06/Introduction-and-Installation-of-CUDA-on-Mac.html">

  <link rel="stylesheet" href="/assets/css/bootstrap.min.css">
  <!-- <link rel="stylesheet" href="/assets/css/icard_resume.css"> -->
  <link rel="stylesheet" href="/assets/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/blog.css" >
  <link rel="stylesheet" href="/assets/css/syntax.css">

  <link rel="icon" type="image/png" href="/assets/img/avatar.JPG">

  <!-- Google fonts -->
  <link rel='stylesheet' href='//fonts.googleapis.com/css?family=Open+Sans:300' type='text/css'>
  <link rel='stylesheet' href='//fonts.googleapis.com/css?family=Source+Sans+Pro' type='text/css'>

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="assets/js/html5shiv.min.js"></script>
  <script src="assets/js/respond.min.js"></script>
  <![endif]-->

</head>

    <body>
        <header class="bloghead">
    <dev class="authorheader">
        <a href="/">
            <img alt="My Avatar" src="/assets/img/avatar.JPG"/>
        </a>
        <dev class="blogtitle">
            <h1><a href="/">Jun Li</a></h1>
            <h5> Hi,everyone! Welcome to My Webpage! </h5>
        </dev>
    </dev>

    <nav class="menu" role="nav">
        <ul>
            <li><a href="/">Home</a></li>
            <li>|</li>
            <li><a href="/menu.html">Menu</a></li>
            <li>|</li>
            <li><a target="_blank" href="https://github.com/junboychina">Github</a></li>
            <li>|</li>
            <li><a target="_blank" href="/about.html"> About Me</a></li>
        </ul>
    </nav>
</header>


        <main class="blogmain">
            <header>
                <h1 class="article-title">Introduction and Installation of CUDA on Mac</h1>
                <p class="article-time">
                    2016年07月06日 Wednesday,  发表于 <span>纽约</span>
                </p>
                <p class="article-hint">
                    如果你对本文有任何的建议或者疑问, 可以在
                    <a href="https://github.com/junboychina/junboychina.github.io/issues" target="_blank">这里给我提 Issues</a>, 谢谢! :)
                </p>
            </header>
            <blockquote>
  <h5 id="you-cant-connect-the-dots-looking-forward-you-can-only-connect-them-looking-backwards-so-you-have-to-trust-that-the-dots-will-somehow-connect-in-yourfuture-you-have-to-trust-in-something----your-gut-destiny-life-karma-whatever-this-approach-has-never-let-me-down-and-it-has-made-all-the-difference-in-my-life--------steve-jobs"><em>“You can’t connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in yourfuture. You have to trust in something – your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.”</em>     —Steve Jobs</h5>
</blockquote>

<p>In this article I will write about parallel programming and CUDA. Also, I will talk about using OpenCV with CUDA which is important for image processing. Hope this article can help you and save your time. Note: This article is for CUDA beginners.</p>

<h2 id="overview">Overview</h2>

<ul>
  <li><strong>Configuration</strong></li>
  <li><strong>Introduction of CUDA</strong></li>
  <li><strong>Installation of CUDA on Mac OS X</strong></li>
  <li><strong>OpenCV with CUDA</strong></li>
  <li><strong>FAQ</strong></li>
  <li><strong>Reference</strong></li>
</ul>

<h2 id="configuration">1. Configuration</h2>

<p>I use my Mac Pro as operating platform. The hardware&amp;software environment and softwares I will install are as follows. You can verify that your system is CUDA-capable here <a href="https://developer.nvidia.com/cuda-gpus">CUDA-supported GPUs</a>. If it is an NVIDIA card that is listed on the CUDA-supported GPUs page, your GPU is CUDA-capable.</p>

<h4 id="hardware-environment">1.1 Hardware environment</h4>
<ul>
  <li><strong>MacBook Pro (Retina, 15-inch, Mid 2014)</strong></li>
  <li><strong>Processor : 2.5 GHz Intel Core i7</strong></li>
  <li><strong>GPU : NVIDIA GeForce GT 750M</strong></li>
</ul>

<h4 id="software-environment">1.2 Software environment</h4>

<ul>
  <li><strong>OS X Yosemite version 10.10.5</strong></li>
  <li><strong>Apple LLVM version 7.0.2 (clang-700.1.81)</strong></li>
  <li><strong>Xcode Version 7.2.1 (7C1002)</strong></li>
</ul>

<h4 id="software-installation">1.3 Software installation</h4>

<ul>
  <li><strong>CUDA 7.5</strong></li>
  <li><strong>OpenCV 3.1.0</strong></li>
</ul>

<h2 id="introduction-of-cuda">2. Introduction of CUDA</h2>

<p>At first, we need to think about the question :</p>

<blockquote>
  <p><em>How does traditional Hardware designer make computers run faster ?</em></p>
</blockquote>

<p>There are mainly three methods :</p>

<ul>
  <li>Faster clocks which means we make a computer works harder !</li>
  <li>Do more computation at every clock cycle which means we make a computer more wise.</li>
  <li>Add more processors which means we ask a lot of small computers work simultaneously <strong>(This is parallel programming)</strong></li>
</ul>

<p>So we know what the parallel programming is.</p>

<p>CUDA is a parallel computing platform and programming model invented by NVIDIA. We use CUDA programming to transfer data from CPU to GPU for parallel computing.</p>

<p>GPU can handle multiple tasks simultaneously because it is optimized for parallel processing. Also it contains lots of simple compute units.</p>

<p>CPU consists of some cores, but it is too few compared with GPU. Also CPU is optimized for sequential serial processing.</p>

<h2 id="installation-of-cuda-on-mac-os-x">3. Installation of CUDA on Mac OS X</h2>

<p>Then I will explain how to install CUDA 7.5 on your computer under OS X.</p>

<h4 id="download-cuda-toolkit-"><strong>3.1 Download CUDA Toolkit :</strong></h4>

<p>NVIDIA CUDA Toolkit is available at <a href="https://developer.nvidia.com/cuda-downloads">CUDA-downloads</a>. You can choose “Full installer” which is a full version. It is called “cuda_7.5.27_mac.dmg “, about 1.0GB.</p>

<h4 id="install-cuda-toolkit"><strong>3.2 Install CUDA Toolkit</strong></h4>

<p>Install it just like you install a common application. Open the “dmg” files you download, launch the installer, follow the on-screen prompts.</p>

<h4 id="set-up-the-environment-variables"><strong>3.3 Set up the Environment variables</strong></h4>

<p>Set up the required environment variables:</p>

<blockquote>
  <p>export PATH=/Developer/NVIDIA/CUDA-7.5/bin:$PATH
export DYLD_LIBRARY_PATH=/Developer/NVIDIA/CUDA-7.5/lib:$DYLD_LIBRARY_PATH</p>
</blockquote>

<h4 id="verification"><strong>3.4 Verification</strong></h4>

<p>After the two steps above, you have successfully installed the CUDA driver and CUDA toolkit. You can check it using <code class="highlighter-rouge">nvcc -V</code> command.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>jundeMacBook-Pro:~ jun$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Mon_Apr_11_13:23:40_CDT_2016
Cuda compilation tools, release 7.5, V7.5.26
</code></pre>
</div>

<h4 id="a-simple-example"><strong>3.5 A simple example</strong></h4>

<p>You can compile and run a simple example using CUDA. The following example is to compute 1^2, 2^2, 3^2, … , 64^2. CPU allocate this task to 64 threads in GPU and they will work simultaneously.
Using command <code class="highlighter-rouge">nvcc -o square square.cu</code>  to compile your “.cu” file, then use command <code class="highlighter-rouge">./square</code> to run it!</p>

<div class="language-c highlighter-rouge"><pre class="highlight"><code><span class="cp">#include &lt;stdio.h&gt;
</span><span class="c1">//This is a simple CUDA example! File name: "square.cu" 
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">square</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span> <span class="n">d_out</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">d_in</span><span class="p">)</span> <span class="p">{</span>
	<span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
	<span class="kt">float</span> <span class="n">f</span> <span class="o">=</span> <span class="n">d_in</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
	<span class="n">d_out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="o">*</span><span class="n">f</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">const</span> <span class="kt">int</span> <span class="n">ARRAY_SIZE</span> <span class="o">=</span> <span class="mi">64</span><span class="p">;</span>
	<span class="k">const</span> <span class="kt">int</span> <span class="n">ARRAY_BYTES</span> <span class="o">=</span> <span class="n">ARRAY_SIZE</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>

	<span class="c1">// generate the input array on the host
</span>	<span class="kt">float</span> <span class="n">h_in</span><span class="p">[</span><span class="n">ARRAY_SIZE</span><span class="p">];</span>
	<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ARRAY_SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">h_in</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kt">float</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
	<span class="p">}</span>
	<span class="kt">float</span> <span class="n">h_out</span><span class="p">[</span><span class="n">ARRAY_SIZE</span><span class="p">];</span>

	<span class="c1">//declare GPU memory pointers
</span>	<span class="kt">float</span> <span class="o">*</span> <span class="n">d_in</span><span class="p">;</span>
	<span class="kt">float</span> <span class="o">*</span> <span class="n">d_out</span><span class="p">;</span>

	<span class="c1">//allocate GPU memory
</span>	<span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">d_in</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">);</span>
	<span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">d_out</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">);</span>

	<span class="c1">//transfer the array to the GPU
</span>	<span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

	<span class="c1">//launch the kernel
</span>	<span class="n">square</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">ARRAY_SIZE</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_out</span><span class="p">,</span> <span class="n">d_in</span><span class="p">);</span>

	<span class="c1">//copy back the result array to the CPU
</span>	<span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">h_out</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

	<span class="c1">//print out the resulting array
</span>	<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ARRAY_SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">printf</span><span class="p">(</span><span class="s">"%f"</span><span class="p">,</span> <span class="n">h_out</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
		<span class="n">printf</span><span class="p">(((</span><span class="n">i</span> <span class="o">%</span> <span class="mi">4</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">)</span> <span class="o">?</span> <span class="s">"</span><span class="se">\t</span><span class="s">"</span> <span class="o">:</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="c1">//free GPU memory allocation
</span>    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_in</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_out</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>	
<span class="p">}</span>
</code></pre>
</div>

<p>After running it, you will get the following result :</p>

<div class="highlighter-rouge"><pre class="highlight"><code>jundeMacBook-Pro:CUDAprogramming jun$ ./square
0.000000	1.000000	4.000000	9.000000
16.000000	25.000000	36.000000	49.000000
64.000000	81.000000	100.000000	121.000000
144.000000	169.000000	196.000000	225.000000
256.000000	289.000000	324.000000	361.000000
400.000000	441.000000	484.000000	529.000000
576.000000	625.000000	676.000000	729.000000
784.000000	841.000000	900.000000	961.000000
1024.000000	1089.000000	1156.000000	1225.000000
1296.000000	1369.000000	1444.000000	1521.000000
1600.000000	1681.000000	1764.000000	1849.000000
1936.000000	2025.000000	2116.000000	2209.000000
2304.000000	2401.000000	2500.000000	2601.000000
2704.000000	2809.000000	2916.000000	3025.000000
3136.000000	3249.000000	3364.000000	3481.000000
3600.000000	3721.000000	3844.000000	3969.000000
</code></pre>
</div>

<p><em>Note:</em> To run CUDA applications on MacBook Pro with both an integrated GPU and a discrete GPU, use the following settings to switch your Graphics to discrete GPU:</p>

<ul>
  <li>Uncheck System Preferences &gt; Energy Saver &gt; Automatic Graphic Switch</li>
  <li>Drag the Computer sleep bar to Never in System Preferences &gt; Energy Saver</li>
</ul>

<h4 id="sample-example-in-cuda"><strong>3.6 Sample example in CUDA</strong></h4>

<p>To fully verify that the compiler works properly, you can also use samples NVIDIA provided. After switching to the directory where the samples were installed, (For example: <code class="highlighter-rouge">cd /Developer/NVIDIA/CUDA-7.5/samples/</code>) then type:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>make -C 0_Simple/vectorAdd
make -C 0_Simple/vectorAddDrv
make -C 1_Utilities/deviceQuery
make -C 1_Utilities/bandwidthTest
</code></pre>
</div>

<p>After compile these samples, you can run them. 
Switching to the directory <code class="highlighter-rouge">cd /Developer/NVIDIA/CUDA-7.5/samples/bin/x86_64/darwin/release</code>, then run</p>

<div class="highlighter-rouge"><pre class="highlight"><code>jundeMacBook-Pro:release jun$ ./vectorAdd 
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>jundeMacBook-Pro:release jun$ ./bandwidthTest 
[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: GeForce GT 750M
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)	Bandwidth(MB/s)
   33554432			1818.5

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)	Bandwidth(MB/s)
   33554432			3253.1

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)	Bandwidth(MB/s)
   33554432			17442.4

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</code></pre>
</div>

<p>You can find something interesting from the result. HAHA, enjoy it~</p>

<div class="highlighter-rouge"><pre class="highlight"><code>jundeMacBook-Pro:release jun$ ./deviceQuery 
./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "GeForce GT 750M"
  CUDA Driver Version / Runtime Version          7.5 / 7.5
  CUDA Capability Major/Minor version number:    3.0
  Total amount of global memory:                 2048 MBytes (2147024896 bytes)
  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores
  GPU Max Clock rate:                            926 MHz (0.93 GHz)
  Memory Clock rate:                             2508 Mhz
  Memory Bus Width:                              128-bit
  L2 Cache Size:                                 262144 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.5, NumDevs = 1, Device0 = GeForce GT 750M
Result = PASS
</code></pre>
</div>

<h2 id="opencv-with-cuda">4. OpenCV with CUDA</h2>
<p>jing qing qi dai, xie xie</p>

<h2 id="faq">5. FAQ</h2>
<p>I met some problems after installation. I have google them but there is no specific answer for these questions. So I decided to write down my solutions for them. Hope this can help you and save your time.</p>

<hr />

<h4 id="q1--when-complie-the-cuda-samples-report-error-as-below"><strong><em>Q1:  When complie the CUDA samples, report error as below</em></strong></h4>

<div class="highlighter-rouge"><pre class="highlight"><code>error: unable to open output file 'vectorAdd.o': 'Permission denied'
1 error generated.
make: *** [vectorAdd.o] Error 1
</code></pre>
</div>

<p><strong><em>A1:</em></strong>  The CUDA samples’ directory is not writable. You just need to add <code class="highlighter-rouge">sudo</code> in front of your command like this <code class="highlighter-rouge">sudo make -C 0_Simple/vectorAdd</code>. Alternatively, you can copy the CUDA samples files to your home directory, then compile them there.</p>

<hr />

<h4 id="q2--still-cannot-find-nvcc-commend-after-install-the-cuda-like-this-nvcc-command-not-found"><strong><em>Q2:  Still Cannot find “nvcc” commend after install the CUDA? like this</em></strong> <code class="highlighter-rouge">nvcc: command not found</code></h4>

<p><strong><em>A2:</em></strong> Actually you have installed the CUDA driver, CUDA Toolkit and CUDA samples after finishing all the steps above. But you didn’t add the path of NVCC to your system. Just like the PATH in Matlab, if the function is not in your current path, you cannot call it. So you cannot call <code class="highlighter-rouge">nvcc</code> complier without specifying the full path of <code class="highlighter-rouge">nvcc</code> in the Terminal.</p>

<p><em>How to add the PATH?</em></p>

<p>Actually, there are totally 3 methods for Bourne Shell environment variable configuration. Remember to make sure your Mac is Bourne Shell, check it using <code class="highlighter-rouge">echo $SHELL</code>. If the output is <code class="highlighter-rouge">bash, zsh, sh</code>, you are using  a kind of Bourne Shell.</p>

<ul>
  <li><code class="highlighter-rouge">~/.bash_profile</code> is executed every time user log in. It is only read by bash.</li>
  <li><code class="highlighter-rouge">/etc/bashrc</code> is for environment variable of system.  It is executed on each instance of the shell.</li>
  <li><code class="highlighter-rouge">/etc/profile</code> is for things that are not specifically related to Bash. Every time you log in, Bash will source <code class="highlighter-rouge">.bash_profile</code>first, if that doesn’t exist, it will source <code class="highlighter-rouge">.profile</code></li>
</ul>

<p><strong><em>The recommended way is by editing your <code class="highlighter-rouge">.bash_profile</code> file. This file is read and the commands in it executed by Bash every time you log in to the system. The following steps I collated are how to add PATH to <code class="highlighter-rouge">.bash_profile</code>.</em></strong></p>

<ol>
  <li>You can check your path like this: <code class="highlighter-rouge">echo $PATH</code></li>
  <li>You will get result like this. There are totally 7 default paths. However, there is no path for CUDA!  That’s why you cannot find nvcc command.</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code>/Users/jun/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin
</code></pre>
</div>

<ol>
  <li>If you have created a <code class="highlighter-rouge">.bash_profile</code> before, you only need to enter  <code class="highlighter-rouge">open ~/.bash_profile</code>. 
Else, you need to create a bash_profile at first, then open it. Like this<code class="highlighter-rouge">touch ~/.bash_profile; open ~/.bash_profile</code></li>
  <li>Write the code below in this file:
 <code class="highlighter-rouge">export LD_LIBRARY_PATH=/usr/local/cuda/lib</code>
 <code class="highlighter-rouge">export PATH=$PATH:/usr/local/cuda/bin</code></li>
  <li>Then save and logout. This will add the PATH of nvcc to your system path automatically every time you login your terminal.</li>
  <li>After relaunched your terminal ! Use <code class="highlighter-rouge">nvcc -V</code> You will find result like this, it illustrates your <code class="highlighter-rouge">nvcc</code>command is available: <code class="highlighter-rouge">nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2015 NVIDIA Corporation</code></li>
  <li>You can also check it like this <code class="highlighter-rouge">echo $PATH</code>, you will find a new path of CUDA at last. Congratulations! You make it!</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code>/Users/jun/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/cuda/bin
</code></pre>
</div>

<h2 id="reference">6. Reference</h2>

<p><a href="http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-mac-os-x/index.html#installation">NVIDIA CUDA documentation</a></p>

<p><a href="http://stackoverflow.com/">Stack Overflow</a></p>

<p><a href="https://www.udacity.com/">Udacity-Parallel programming</a></p>


            <footer class="article-footer">
    <div class="authorimage">
        <img src="/assets/img/avatar.JPG" alt="My Avatar" class="img-circle">
    </div>
    <section class="author">
        <h4><a href="/about.html">junboychina</a></h4>
        <a href="mailto:jl7333@nyu.edu">jl7333@nyu.edu</a>
    </section>
</footer>

        </main>

        <div class="footer-copyright">
    <div class="container-fluid">
        <div class="row-fluid">
            <div class="col-md-12">
                Copyright &copy; 2016 Jun Li - All rights reserved.
            </div>
        </div>
    </div>
</div>
<script type="text/javascript" src="/assets/js/jquery.min.js"></script>
<script type="text/javascript" src="/assets/js/bootstrap.min.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74743250-2', 'auto');
  ga('send', 'pageview');

</script>


    </body>

</html>
